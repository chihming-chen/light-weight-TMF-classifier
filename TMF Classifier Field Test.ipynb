{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light-weight TMF Classifier - Field Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Job Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subartifact</th>\n",
       "      <th>Artifact #</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNPK1007 update</td>\n",
       "      <td>Relevant Communications</td>\n",
       "      <td>99.00.14</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Change Order Fee</td>\n",
       "      <td>Invoices</td>\n",
       "      <td>05.04.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Subartifact  \\\n",
       "0                                    RNPK1007 update  Relevant Communications   \n",
       "1  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...                  Minutes   \n",
       "2  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...                  Minutes   \n",
       "3  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...                  Minutes   \n",
       "4                             Total Change Order Fee                 Invoices   \n",
       "\n",
       "  Artifact # email  \n",
       "0   99.00.14     X  \n",
       "1   99.00.19   NaN  \n",
       "2   99.00.19   NaN  \n",
       "3   99.00.19   NaN  \n",
       "4   05.04.07   NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read selected columns from the TMF Reference Model's speccifications\n",
    "job = pd.read_csv(\"data/01/field_data.csv\")\n",
    "job.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expecting some of the job data is not labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unlabeled data\n",
    "job.dropna(subset=['Title', 'Artifact #'], axis=0, inplace=True)\n",
    "job.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jimmy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jimmy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jimmy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# Custom transformer using NLTK PorterStemmer and tokenizer\n",
    "class StemmingTransformer():\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.transform_time = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self    \n",
    "\n",
    "    def stem_text(self, text):\n",
    "        return \" \".join([self.stemmer.stem(token) for token in nltk.word_tokenize(text)])\n",
    "\n",
    "    def transform(self, X):\n",
    "        start_time_ = time.time()\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            X_transformed = list(executor.map(self.stem_text, X))\n",
    "        \n",
    "        self.transform_time = time.time() - start_time_\n",
    "        return X_transformed    \n",
    "\n",
    "# Custom transformer using NLTK lemmatizer and tokenizer\n",
    "class LemmatizingTransformer():\n",
    "    def __init__(self):\n",
    "        self.stemmer = WordNetLemmatizer()\n",
    "        self.transform_time = None\n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def stem_text(self, text):\n",
    "        return \" \".join([self.stemmer.lemmatize(token) for token in nltk.word_tokenize(text)])\n",
    "\n",
    "    def transform(self, X):\n",
    "        start_time_ = time.time()\n",
    "        X_transformed = [\" \".join([self.stemmer.lemmatize(token) for token in word_tokenize(text)]) for text in X]\n",
    "        self.transform_time = time.time() - start_time_\n",
    "        return X_transformed\n",
    "\n",
    "# Download required NLTK data \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed: 0.0560\n",
      "93 rows\n"
     ]
    }
   ],
   "source": [
    "input_var  = 'Title'\n",
    "target = 'Artifact #'\n",
    "\n",
    "stemmer = StemmingTransformer()\n",
    "job['stem'] = stemmer.transform(job[input_var])\n",
    "print(f'Time lapsed: {stemmer.transform_time:.4f}')\n",
    "print(f'{job.shape[0]} rows')\n",
    "X, y = job[['stem']], job[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Model pre-trained with TMF Referende Model specificaitons\n",
    "version = '0.1'\n",
    "model_filename =  f\"TMF_classifier_v{version}.joblib\"\n",
    "tmf_classifier = load(model_filename)\n",
    "\n",
    "# Pre-trained model with GPT-augmented, synthetic training data\n",
    "gpt_model_filename =  f\"TMF_classifier_gpt_v{version}.joblib\"\n",
    "gpt_classifier = load(gpt_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMF model Score: 0.440860\n",
      "GPT-enhanced model Score: 0.419355\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    preditions = model.predict(X)\n",
    "    score = model.score(X, y)\n",
    "    hit, miss = [], []\n",
    "    for real, predicted in zip (y, preditions):\n",
    "        if real == predicted:\n",
    "            hit.append({'Actual': real, 'Predicted': predicted})\n",
    "        else:\n",
    "            miss.append({'Actual': real, 'Predicted': predicted})\n",
    "    # convert to DataFrames\n",
    "    hit = pd.DataFrame(hit)\n",
    "    miss = pd.DataFrame(miss)\n",
    "    return score, hit, miss\n",
    "\n",
    "tmf_score, tmf_hit, tmf_miss = evaluate_model(tmf_classifier, X, y)\n",
    "print(f\"TMF model Score: {tmf_score:.6f}\")\n",
    "\n",
    "gpt_score, gpt_hit, gpt_miss = evaluate_model(gpt_classifier, X, y)\n",
    "print(f\"GPT-enhanced model Score: {gpt_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expending Training Data from Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'model': ['Logistic', 'Decision Tree', 'Bayes'], \n",
    "#              'best_params': ['', '', ''],\n",
    "#              'best_score': ['', '', '']}).set_index('model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job.drop(columns=['Subartifact', 'email']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:1.3975207805633545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artifact #</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNPK1007 update</td>\n",
       "      <td>99.00.14</td>\n",
       "      <td>rnpk1007 updat</td>\n",
       "      <td>RNPK1007 update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "      <td>Salix RNPK1007 ( CA25187 ) Proiect Status Date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "      <td>Salix RNPK1007 ( CA25187 ) Proiect Status Date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salix RNPK1007 (CA25187) Proiect Status\\nDate ...</td>\n",
       "      <td>99.00.19</td>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "      <td>Salix RNPK1007 ( CA25187 ) Proiect Status Date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Change Order Fee</td>\n",
       "      <td>05.04.07</td>\n",
       "      <td>total chang order fee</td>\n",
       "      <td>Total Change Order Fee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Artifact #  \\\n",
       "0                                    RNPK1007 update   99.00.14   \n",
       "1  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...   99.00.19   \n",
       "2  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...   99.00.19   \n",
       "3  Salix RNPK1007 (CA25187) Proiect Status\\nDate ...   99.00.19   \n",
       "4                             Total Change Order Fee   05.04.07   \n",
       "\n",
       "                                                stem  \\\n",
       "0                                     rnpk1007 updat   \n",
       "1  salix rnpk1007 ( ca25187 ) proiect statu date ...   \n",
       "2  salix rnpk1007 ( ca25187 ) proiect statu date ...   \n",
       "3  salix rnpk1007 ( ca25187 ) proiect statu date ...   \n",
       "4                              total chang order fee   \n",
       "\n",
       "                                               lemma  \n",
       "0                                    RNPK1007 update  \n",
       "1  Salix RNPK1007 ( CA25187 ) Proiect Status Date...  \n",
       "2  Salix RNPK1007 ( CA25187 ) Proiect Status Date...  \n",
       "3  Salix RNPK1007 ( CA25187 ) Proiect Status Date...  \n",
       "4                             Total Change Order Fee  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var = 'Title'\n",
    "lemmatizer = LemmatizingTransformer()\n",
    "df['lemma'] = lemmatizer.transform(df[input_var])\n",
    "print(f'Time lapsed:{lemmatizer.transform_time}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Base Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artifact #</th>\n",
       "      <th>Subartifact Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.01</td>\n",
       "      <td>document transfer documentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.01</td>\n",
       "      <td>evidence of quality review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.01</td>\n",
       "      <td>request to lock tmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.01</td>\n",
       "      <td>trial master file plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.01</td>\n",
       "      <td>trial master file index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>11.03.09</td>\n",
       "      <td>study-level submission dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>11.04.01</td>\n",
       "      <td>interim statistical summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>11.04.01</td>\n",
       "      <td>mid-trial statistical report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11.04.02</td>\n",
       "      <td>final statistical summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>11.04.02</td>\n",
       "      <td>end-of-trial statistical report</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Artifact #                Subartifact Title\n",
       "0    01.01.01  document transfer documentation\n",
       "1    01.01.01       evidence of quality review\n",
       "2    01.01.01              request to lock tmf\n",
       "3    01.01.01           trial master file plan\n",
       "4    01.01.01          trial master file index\n",
       "..        ...                              ...\n",
       "89   11.03.09   study-level submission dataset\n",
       "90   11.04.01      interim statistical summary\n",
       "91   11.04.01     mid-trial statistical report\n",
       "92   11.04.02        final statistical summary\n",
       "93   11.04.02  end-of-trial statistical report\n",
       "\n",
       "[624 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read selected columns from the TMF Reference Model's speccifications\n",
    "labeled_data_file = \"data/labeled_training_sets.xlsx\"\n",
    "base_training_sets = ['TMF 3.3', 'GPT-1-5']\n",
    "labeled_data = pd.DataFrame()\n",
    "\n",
    "for training_set in base_training_sets:\n",
    "    labeled_data = pd.concat([labeled_data, \n",
    "                              pd.read_excel(labeled_data_file, \n",
    "                                            sheet_name=training_set,\n",
    "                                            usecols=\"B, C\",header=0,)]\n",
    "                            )\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemminig time lapsed: 0.1258\n",
      "624 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnpk1007 updat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salix rnpk1007 ( ca25187 ) proiect statu date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total chang order fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>transfer of regulatori oblig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>trial-specif sop plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>key vendor personnel approv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>certif of liabil insur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>audit certif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 stem\n",
       "0                                      rnpk1007 updat\n",
       "1   salix rnpk1007 ( ca25187 ) proiect statu date ...\n",
       "2   salix rnpk1007 ( ca25187 ) proiect statu date ...\n",
       "3   salix rnpk1007 ( ca25187 ) proiect statu date ...\n",
       "4                               total chang order fee\n",
       "..                                                ...\n",
       "91                       transfer of regulatori oblig\n",
       "92                              trial-specif sop plan\n",
       "93                        key vendor personnel approv\n",
       "94                             certif of liabil insur\n",
       "95                                       audit certif\n",
       "\n",
       "[93 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.rename(columns={'Subartifact Title': 'Title'}, inplace=True)\n",
    "input_var  = 'Title'\n",
    "target = 'Artifact #'\n",
    "\n",
    "stemmer = StemmingTransformer()\n",
    "labeled_data['stem'] = stemmer.transform(labeled_data[input_var])\n",
    "print(f'Stemminig time lapsed: {stemmer.transform_time:.4f}')\n",
    "\n",
    "# lemmatizer = LemmatizingTransformer()\n",
    "# labeled_data['lemma'] = lemmatizer.transform(labeled_data[input_var])\n",
    "# print(f'Lemmatization time lapsed:{lemmatizer.transform_time:4f}')\n",
    "\n",
    "labeled_data.head()\n",
    "print(f'{labeled_data.shape[0]} rows')\n",
    "\n",
    "X_base, y_base = labeled_data[['stem']], labeled_data[target]\n",
    "\n",
    "column_name = 'stem'\n",
    "target = 'Artifact #'\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "X, y = df[[column_name]], df[target]\n",
    "\n",
    "# Not emough training data for grid_search\n",
    "# X_base = pd.concat([X_base, X_base, X_base, X_base, X_base])\n",
    "# y_base = pd.concat([y_base, y_base, y_base, y_base, y_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate = 0.10, Accuracy score = 0.56\n",
      "Sampling rate = 0.20, Accuracy score = 0.63\n",
      "Sampling rate = 0.30, Accuracy score = 0.65\n",
      "Sampling rate = 0.40, Accuracy score = 0.71\n",
      "Sampling rate = 0.50, Accuracy score = 0.72\n",
      "Sampling rate = 0.60, Accuracy score = 0.79\n",
      "Sampling rate = 0.70, Accuracy score = 0.68\n",
      "Sampling rate = 0.80, Accuracy score = 0.68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampling Rate</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.559524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sampling Rate  Test Score\n",
       "0            0.1    0.559524\n",
       "1            0.2    0.626667\n",
       "2            0.3    0.651515\n",
       "3            0.4    0.714286\n",
       "4            0.5    0.723404\n",
       "5            0.6    0.789474\n",
       "6            0.7    0.678571\n",
       "7            0.8    0.684211"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_stop_words = ['a', 'of', 'and', 'for', 'to', \n",
    "                 'document', 'documentation', 'plan', 'letter', 'form',\n",
    "                 'information'\n",
    "                ]  \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                  stop_words=stopwords.words('english'),\n",
    "                                  lowercase=True), 'stem')\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "     ])\n",
    "\n",
    "\n",
    "score = []\n",
    "# Run search on stemmed and lemmatized tokens\n",
    "for sampling_rate in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    # Use differnt sampling rate each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        train_size=sampling_rate,\n",
    "                                                        random_state=32\n",
    "                                                       )\n",
    "\n",
    "    # Add labeled base training data\n",
    "    X_train = pd.concat([X_base, X_train], axis=0, ignore_index=True)\n",
    "    y_train = pd.concat([y_base, y_train], axis=0)\n",
    "    best_model = pipeline.fit(X_train, y_train)\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    score.append({'Sampling Rate': sampling_rate, 'Test Score': test_score})\n",
    "    print(f\"Sampling rate = {sampling_rate:.2f}, Accuracy score = {test_score:.2f}\")\n",
    "score = pd.DataFrame(score)\n",
    "score\n",
    "# # Missed predictions\n",
    "# if pre_train_score < 1:\n",
    "#     print(\"Missed Predictions:\")\n",
    "#     preditions = best_model.predict(X)\n",
    "#     missed = []\n",
    "#     for real, predicted in zip (y, preditions):\n",
    "#         if real != predicted:\n",
    "#             missed.append({'Actual': real, 'Predicted': predicted})\n",
    "\n",
    "#     missed = pd.DataFrame(missed)\n",
    "#     print(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
